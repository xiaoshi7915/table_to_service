"""
æ€§èƒ½ç›‘æ§æ¨¡å—
è·Ÿè¸ªå„æ­¥éª¤è€—æ—¶ï¼Œè®°å½•ç¼“å­˜å‘½ä¸­ç‡ï¼Œç›‘æ§LLMè°ƒç”¨æ—¶é—´
"""
import time
from typing import Dict, Any, Optional, Callable
from functools import wraps
from loguru import logger
from contextlib import contextmanager


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.metrics: Dict[str, Any] = {
            "cache_hits": 0,
            "cache_misses": 0,
            "llm_calls": 0,
            "llm_total_time": 0.0,
            "sql_executions": 0,
            "sql_total_time": 0.0,
            "sql_cache_hits": 0,
            "sql_cache_misses": 0,
            "schema_loads": 0,
            "schema_total_time": 0.0,
            "schema_cache_hits": 0,
            "schema_cache_misses": 0,
        }
    
    def record_cache_hit(self, cache_type: str = "general"):
        """è®°å½•ç¼“å­˜å‘½ä¸­"""
        self.metrics["cache_hits"] += 1
        if cache_type == "sql":
            self.metrics["sql_cache_hits"] += 1
        elif cache_type == "schema":
            self.metrics["schema_cache_hits"] += 1
    
    def record_cache_miss(self, cache_type: str = "general"):
        """è®°å½•ç¼“å­˜æœªå‘½ä¸­"""
        self.metrics["cache_misses"] += 1
        if cache_type == "sql":
            self.metrics["sql_cache_misses"] += 1
        elif cache_type == "schema":
            self.metrics["schema_cache_misses"] += 1
    
    def record_llm_call(self, duration: float):
        """è®°å½•LLMè°ƒç”¨"""
        self.metrics["llm_calls"] += 1
        self.metrics["llm_total_time"] += duration
    
    def record_sql_execution(self, duration: float, from_cache: bool = False):
        """è®°å½•SQLæ‰§è¡Œ"""
        self.metrics["sql_executions"] += 1
        self.metrics["sql_total_time"] += duration
        if from_cache:
            self.record_cache_hit("sql")
        else:
            self.record_cache_miss("sql")
    
    def record_schema_load(self, duration: float, from_cache: bool = False):
        """è®°å½•SchemaåŠ è½½"""
        self.metrics["schema_loads"] += 1
        self.metrics["schema_total_time"] += duration
        if from_cache:
            self.record_cache_hit("schema")
        else:
            self.record_cache_miss("schema")
    
    def get_cache_hit_rate(self, cache_type: str = "general") -> float:
        """è·å–ç¼“å­˜å‘½ä¸­ç‡"""
        if cache_type == "sql":
            total = self.metrics["sql_cache_hits"] + self.metrics["sql_cache_misses"]
            if total == 0:
                return 0.0
            return self.metrics["sql_cache_hits"] / total
        elif cache_type == "schema":
            total = self.metrics["schema_cache_hits"] + self.metrics["schema_cache_misses"]
            if total == 0:
                return 0.0
            return self.metrics["schema_cache_hits"] / total
        else:
            total = self.metrics["cache_hits"] + self.metrics["cache_misses"]
            if total == 0:
                return 0.0
            return self.metrics["cache_hits"] / total
    
    def get_avg_llm_time(self) -> float:
        """è·å–å¹³å‡LLMè°ƒç”¨æ—¶é—´"""
        if self.metrics["llm_calls"] == 0:
            return 0.0
        return self.metrics["llm_total_time"] / self.metrics["llm_calls"]
    
    def get_avg_sql_time(self) -> float:
        """è·å–å¹³å‡SQLæ‰§è¡Œæ—¶é—´"""
        if self.metrics["sql_executions"] == 0:
            return 0.0
        return self.metrics["sql_total_time"] / self.metrics["sql_executions"]
    
    def get_avg_schema_time(self) -> float:
        """è·å–å¹³å‡SchemaåŠ è½½æ—¶é—´"""
        if self.metrics["schema_loads"] == 0:
            return 0.0
        return self.metrics["schema_total_time"] / self.metrics["schema_loads"]
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        return {
            "cache_hit_rate": self.get_cache_hit_rate(),
            "sql_cache_hit_rate": self.get_cache_hit_rate("sql"),
            "schema_cache_hit_rate": self.get_cache_hit_rate("schema"),
            "llm_calls": self.metrics["llm_calls"],
            "avg_llm_time": self.get_avg_llm_time(),
            "sql_executions": self.metrics["sql_executions"],
            "avg_sql_time": self.get_avg_sql_time(),
            "schema_loads": self.metrics["schema_loads"],
            "avg_schema_time": self.get_avg_schema_time(),
        }
    
    def reset(self):
        """é‡ç½®æŒ‡æ ‡"""
        self.metrics = {
            "cache_hits": 0,
            "cache_misses": 0,
            "llm_calls": 0,
            "llm_total_time": 0.0,
            "sql_executions": 0,
            "sql_total_time": 0.0,
            "sql_cache_hits": 0,
            "sql_cache_misses": 0,
            "schema_loads": 0,
            "schema_total_time": 0.0,
            "schema_cache_hits": 0,
            "schema_cache_misses": 0,
        }


# å…¨å±€æ€§èƒ½ç›‘æ§å™¨å®ä¾‹
_performance_monitor: Optional[PerformanceMonitor] = None


def get_performance_monitor() -> PerformanceMonitor:
    """è·å–å…¨å±€æ€§èƒ½ç›‘æ§å™¨å®ä¾‹"""
    global _performance_monitor
    if _performance_monitor is None:
        _performance_monitor = PerformanceMonitor()
    return _performance_monitor


@contextmanager
def track_time(operation_name: str, logger_instance=None):
    """
    è·Ÿè¸ªæ“ä½œæ—¶é—´çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    
    Args:
        operation_name: æ“ä½œåç§°
        logger_instance: æ—¥å¿—è®°å½•å™¨ï¼ˆå¯é€‰ï¼‰
    
    Yields:
        å¼€å§‹æ—¶é—´æˆ³
    """
    start_time = time.time()
    log = logger_instance or logger
    
    try:
        yield start_time
    finally:
        duration = time.time() - start_time
        log.info(f"â±ï¸  {operation_name} è€—æ—¶: {duration:.3f}ç§’")


def track_llm_call(func: Callable):
    """
    è£…é¥°å™¨ï¼šè·Ÿè¸ªLLMè°ƒç”¨æ—¶é—´
    
    Args:
        func: è¦è£…é¥°çš„å‡½æ•°
    
    Returns:
        è£…é¥°åçš„å‡½æ•°
    """
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            duration = time.time() - start_time
            get_performance_monitor().record_llm_call(duration)
            logger.debug(f"LLMè°ƒç”¨ {func.__name__} è€—æ—¶: {duration:.3f}ç§’")
            return result
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"LLMè°ƒç”¨ {func.__name__} å¤±è´¥ï¼Œè€—æ—¶: {duration:.3f}ç§’ï¼Œé”™è¯¯: {e}")
            raise
    
    return wrapper


def log_performance_summary():
    """è®°å½•æ€§èƒ½æ‘˜è¦"""
    monitor = get_performance_monitor()
    summary = monitor.get_summary()
    
    logger.info("=" * 60)
    logger.info("ğŸ“Š æ€§èƒ½ç›‘æ§æ‘˜è¦")
    logger.info(f"ç¼“å­˜å‘½ä¸­ç‡: {summary['cache_hit_rate']:.2%}")
    logger.info(f"SQLç¼“å­˜å‘½ä¸­ç‡: {summary['sql_cache_hit_rate']:.2%}")
    logger.info(f"Schemaç¼“å­˜å‘½ä¸­ç‡: {summary['schema_cache_hit_rate']:.2%}")
    logger.info(f"LLMè°ƒç”¨æ¬¡æ•°: {summary['llm_calls']}, å¹³å‡è€—æ—¶: {summary['avg_llm_time']:.3f}ç§’")
    logger.info(f"SQLæ‰§è¡Œæ¬¡æ•°: {summary['sql_executions']}, å¹³å‡è€—æ—¶: {summary['avg_sql_time']:.3f}ç§’")
    logger.info(f"SchemaåŠ è½½æ¬¡æ•°: {summary['schema_loads']}, å¹³å‡è€—æ—¶: {summary['avg_schema_time']:.3f}ç§’")
    logger.info("=" * 60)

